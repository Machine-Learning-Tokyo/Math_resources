# Free online math resources for Machine Learning

# Content

- [Books](#books)
- [Interactive Tools](#interactive-tools)
- [Videos](#videos)
- [Online courses](#online-courses)


# Books

## Dive into Deep Learning

An interactive deep learning book with code, math, and discussions, based on the NumPy interface by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. With 900 pages, this seems to be one of the most comprehensive one-stop resources that goes from Linear Neural Networks and Multilayer Perceptrons all the way to modern Deep Learning architectures including Attention Mechanisms and Optimization Algorithms ‚Äì giving you all three: Theory, Math & Code.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/Math_resources/blob/master/images/d2lai.png" width="800"></p>](http://d2l.ai/)

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/Math_resources/blob/master/images/d2lai.gif" width="600"></p>](http://d2l.ai/)


## Math for Machine Learning

Note: We have bi-weekly remote reading sessions goingthrough all chapters of the book. If you'd like to join check out this [blog post](https://machinelearningtokyo.com/2019/11/28/ml-math-reading-sessions/) and join us on [Meetup](https://www.meetup.com/Machine-Learning-Tokyo/).

**Part I: Mathematical Foundations**

1. Introduction and Motivation
2. Linear Algebra
3. Analytic Geometry
4. Matrix Decompositions
5. Vector Calculus
6. Probability and Distribution
7. Continuous Optimization

**Part II: Central Machine Learning Problems**

8. When Models Meet Data
9. Linear Regression
10. Dimensionality Reduction with Principal Component Analysis
11. Density Estimation with Gaussian Mixture Models
12. Classification with Support Vector Machines

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/Math_resources/blob/master/images/ml_math.png" width="800"></p>](https://mml-book.github.io/)

# Interactive tools

## Seeing Theory: Probability and Stats
A visual introduction to probability and statistics.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/Math_resources/blob/master/images/seeing_theory.png" width="800"></p>](https://seeing-theory.brown.edu/)

## Sage Interactions

This is a collection of pages demonstrating the use of the **interact** command in Sage. It should be easy to just scroll through and copy/paste examples into Sage notebooks. 

Examples include Algebra, Bioinformatics, Calculus, Cryptography, Differential Equations, Drawing Graphics, Dynamical Systems, Fractals, Games and Diversions, Geometry, Graph Theory, Linear Algebra, Loop Quantum Gravity, Number Theory, Statistics/Probability, Topology, Web Applications.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/sage.png" width="1000"></p>](https://wiki.sagemath.org/interact/)


## Probability Distributions

by Simon Ward-Jones. A visual üëÄ tour of probability distributions.

- Bernoulli Distribution
- Binomial Distribution
- Normal Distribution
- Beta Distribution
- LogNormal Distribution

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/prob.png" width="1000"></p>](https://www.simonwardjones.co.uk/posts/probability_distributions/)

## Bayesian Inference

by Simon Ward-Jones. Explaining the basics of bayesian inference with the example of flipping a coin.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/DL_study_group/blob/master/images/bayes.png" width="1000"></p>](https://www.simonwardjones.co.uk/posts/probability_distributions/)



# Videos

## 3blue1brown

3blue1brown, by Grant Sanderson, is some combination of math and entertainment, depending on your disposition. The goal is for explanations to be driven by animations and for difficult problems to be made simple with changes in perspective.

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/Math_resources/blob/master/images/3blue1brown.png" width="800"></p>](https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/featured)

## Recommended video series:
- **[Essence of Linear Algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)**
- **[Essence of Calculus](https://www.youtube.com/playlist?list=PLZHQObOWTQDMsr9K-rj53DwVRMYO3t5Yr)**


## The classic: Gilbert Strang MIT lectures on Linear Algebra

**Matrix Methods in Data Analysis, Signal Processing, and Machine Learning**
- **Spring 2018**
- **Level:** Undergraduate / Graduate
- **Course description:** "Linear algebra concepts are key for understanding and creating machine learning algorithms, especially as applied to deep learning and neural networks. This course reviews linear algebra with applications to probability and statistics and optimization‚Äìand above all a full explanation of deep learning."
- **Format:** [Video lectures](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/)

[<p align="center"><img src="https://github.com/Machine-Learning-Tokyo/Math_resources/blob/master/images/gilbert_strang.png" width="600"></p>](https://ocw.mit.edu/courses/mathematics/18-065-matrix-methods-in-data-analysis-signal-processing-and-machine-learning-spring-2018/video-lectures/index.htm)

# Online courses

## Mathematics for Machine Learning ‚Äì¬†Linear Algebra

Imperial College London. "This course offers an introduction to the linear algebra required for common machine learning techniques. We start at the very beginning with thinking about vectors and what vectors are, and the basic mathematical operations we can do with vectors, like how to add vectors. We then move on to think about how to find the product of vectors and what the modulus or size of a vector is. In physical spaces that then lets us think about linear algebra geometrically, and therefore when vectors are perpendicular to eachother or have an angle between then.  We can think about the basis ‚Äì the fundamental vectors that make up a vector space ‚Äì and how to change basis and transform between vector frames.  That then lets us think about how to combine matrix transformations and how to do inverse transformations. That then takes us on to think about the eigenvectors and eigenvalues of a transformation and what these ‚Äúeigen-things‚Äù mean. We then finish up the course by applying all this to a machine learning problem ‚Äì the google pagerank algorithm."

- [YouTube Playlist](https://www.youtube.com/playlist?list=PLiiljHvN6z1_o1ztXTKWPrShrMrBLo5P3)
- [Coursera](https://www.coursera.org/specializations/mathematics-machine-learning)

## Essential Math for Machine Learning: Python Edition

- Equations, Functions, and Graphs
- Differentiation and Optimization
- Vectors and Matrices
- Statistics and Probability

- [EdX](https://www.edx.org/course/essential-math-for-machine-learning-python-edition-3)
